{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:small_sklearn] *",
      "language": "python",
      "name": "conda-env-small_sklearn-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Sentiment Analysis and Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYqFfL7XReQb"
      },
      "source": [
        "In this workbook, I have built a lagistic regression model to classify the sentiment from feedback text. \n",
        "The Sentiment is either 0 or 1 \n",
        "where 0 is not happy\n",
        "and 1 is happy \n",
        "\n",
        "At the end, I take 5 random misclassified examples to analysis the performance of the logistic regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raXNheUCRljW"
      },
      "source": [
        "### Loading and Prep\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztkP9skQRljX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce05a55-f289-4998-f9a2-bd2553dfb910"
      },
      "source": [
        "# Import the relevant libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import ngrams\n",
        "\n",
        "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
        "\n",
        "print(df_train.info())\n",
        "print(df_train.head())\n",
        "\n",
        "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
        "\n",
        "print(df_test.info())\n",
        "print(df_test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2400 entries, 0 to 2399\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2400 non-null   object\n",
            " 1   Polarity  2400 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 37.6+ KB\n",
            "None\n",
            "                                            Sentence  Polarity\n",
            "0                           Wow... Loved this place.         1\n",
            "1                                 Crust is not good.         0\n",
            "2          Not tasty and the texture was just nasty.         0\n",
            "3  Stopped by during the late May bank holiday of...         1\n",
            "4  The selection on the menu was great and so wer...         1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600 entries, 0 to 599\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  600 non-null    object\n",
            " 1   Polarity  600 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 9.5+ KB\n",
            "None\n",
            "                                            Sentence  Polarity\n",
            "0  A good commentary of today's love and undoubte...         1\n",
            "1  For people who are first timers in film making...         1\n",
            "2  It was very popular when I was in the cinema, ...         1\n",
            "3  It's a feel-good film and that's how I felt wh...         1\n",
            "4  It has northern humour and positive about the ...         1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsGDl4_zAZgV"
      },
      "source": [
        "**Preprocessing of the text**\n",
        "\n",
        "Step 1) Text Cleaning:\n",
        "- Normalizing all the words to lower (Why? So that model doesn't treat \"Great\" or \"great\" differently)\n",
        "- Removing stop words (Why? Some prevalent words such as 'the', 'is' doesn't add any value)\n",
        "- Lemmetization (Why? Returns the root form of a word and thus helping the model treat words such as \"Liked\" and \"Like\" as same)\n",
        "\n",
        "Step 2) Feature extraction:\n",
        "- TF-IDF extraction (term frequency inverse document frequency) - This extraction technique will return a bag of words matrix for words and n-grams. The matrix will have the columns as the words and n-grams, while the values will be each word's tfidf value.\n",
        "- TF-IDF is a better feature extraction method in our case as by taking into account the frequency of the word across the all documents it can reduce the weight of prevalent words while increasing the weight of less frequent but important words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB4ZnHBO4Fw6"
      },
      "source": [
        "###########************************** Proprocessing of text *************************#################\n",
        "\n",
        "\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "# Stopwords updated list - These negation words will help model learn the negative sentiment \n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "exclude_words = set((\"not\", \"no\", \"against\",\"mustn't\",\"needn't\",\"shouldn't\",\"won't\", \"wouldn't\"))\n",
        "new_stop_words = stop_words.difference(exclude_words)\n",
        " \n",
        "################################### Step 1- Clean the Sentence ########################################\n",
        "def clean_data(text):\n",
        "    punct = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    txt = re.split('\\W+',punct)    \n",
        "    doc = nlp(\" \".join(txt))\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "df_train[\"clean_sentence\"] = df_train.Sentence.apply(clean_data)\n",
        "\n",
        "\n",
        "################################## Step 2 - Feature Extraction using TF-IDF ############################\n",
        "vectorizer = TfidfVectorizer(\n",
        "                             stop_words = new_stop_words,\n",
        "                             max_df = 0.4, \n",
        "                             min_df=2,\n",
        "                             max_features = 2000,\n",
        "                             ngram_range=[1,3])\n",
        "def fit_features(df):\n",
        "  global dtm\n",
        "  dtm = vectorizer.fit(df)\n",
        "  return\n",
        "\n",
        "def transform_features(df):\n",
        "  global dtm\n",
        " \n",
        "  if dtm is None:\n",
        "    print(\"Need to call fit_features first!\")\n",
        "    return\n",
        "\n",
        "  dtm = vectorizer.transform(df)\n",
        "\n",
        "  features = pd.DataFrame(dtm.toarray(), \n",
        "                      columns=[f'{name}' for name in \n",
        "                               vectorizer.get_feature_names()], \n",
        "                      index=df.index)\n",
        "  \n",
        "  return features\n",
        "\n",
        "X_train,y_train = df_train.loc[:,\"clean_sentence\"], df_train.loc[:,\"Polarity\"]\n",
        "fit_features(X_train)\n",
        "X_train_features = transform_features(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD6MH0BNRljY"
      },
      "source": [
        "### Modeling\n",
        "\n",
        "Using my favourite ML model Logistic Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcd-Xx35B1Uv"
      },
      "source": [
        "**Importing all the relevant modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qpq0czfKbm2"
      },
      "source": [
        "##### Importing the relevant packages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7R-AuvLCG3X"
      },
      "source": [
        "**Model Training with hyperparamter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUJCI7SfNx8N"
      },
      "source": [
        "- Hyperparameter tuning:\n",
        "\n",
        "Two hyperparameters are tuned \n",
        "1) class_weight - 'Balance' or 'None'\n",
        "2) C - Regularization parameter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Cross validation:\n",
        "\n",
        "Cross validation is done using 3 fold \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Handled imbalanced data:\n",
        "\n",
        "Data imbalance handled by tuning 'class_weight' parameter\n",
        "\n",
        "\n",
        "\n",
        "- Features scaled:\n",
        "\n",
        "Features are scaled using MinMaxScaler (range 0-1).\n",
        "Scaling the features help Logistic regression in convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoHBIcfeCL76"
      },
      "source": [
        "pipeline = Pipeline([('scaler', MinMaxScaler()), \n",
        "                    ('LR', LogisticRegression(random_state=21))])\n",
        "\n",
        "param_grid = {\n",
        "                \"LR__class_weight\":['balanced', None],\n",
        "                \"LR__C\":[100,10,1,0.5,0.1]\n",
        "                } \n",
        "\n",
        "lr_grid = GridSearchCV(pipeline,param_grid,cv=3,n_jobs=-1, scoring='f1')\n",
        "model_lr = lr_grid.fit(X_train_features, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2y-ZXOkFYD-",
        "outputId": "9437c0d0-e3b2-4d12-a8df-4de6536434df"
      },
      "source": [
        "print(f\"Best Parameters of LR model : {model_lr.best_params_}\")\n",
        "print(f\"\\nBest Cross validation Score {model_lr.best_score_:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters of LR model : {'LR__C': 0.5, 'LR__class_weight': 'balanced'}\n",
            "\n",
            "Best Cross validation Score 0.791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6tKHWGYRljY"
      },
      "source": [
        "### Assessing\n",
        "\n",
        "- Test data is tranformed using the transformation function 'transform_features'\n",
        "\n",
        "- Prediction is made using predict function\n",
        "\n",
        "- Accuracy and f1 score of the model on Test is printed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkDB1A3WRljY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f71eaae-9863-418d-92e9-25ee9a816871"
      },
      "source": [
        "df_test[\"clean_sentence\"] = df_test.Sentence.apply(clean_data)\n",
        "X_test,y_test = df_test[\"clean_sentence\"], df_test[\"Polarity\"]\n",
        "X_test_features = transform_features(X_test)\n",
        "\n",
        "y_pred = model_lr.predict(X_test_features)\n",
        "y_probablity = model_lr.predict_proba(X_test_features)[:,1]\n",
        "\n",
        "print(f\"Accuracy of the model on Test: {accuracy_score(y_test,y_pred):.3f}\")\n",
        "print(f\"\\nF1 score of the model on Test: {f1_score(y_test,y_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on Test: 0.762\n",
            "\n",
            "F1 score of the model on Test: 0.753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H6BXfQnWiPS",
        "outputId": "ecac2e7f-754f-4220-cf9d-781682a8e58b"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test,y_pred))\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "\n",
        "print(f\"true negative :  {tn}\")\n",
        "print(f\"false positive:  {fp}\")\n",
        "print(f\"false negative:  {fn}\")\n",
        "print(f\"true positive :  {tp}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.83      0.77       287\n",
            "           1       0.82      0.70      0.75       313\n",
            "\n",
            "    accuracy                           0.76       600\n",
            "   macro avg       0.77      0.76      0.76       600\n",
            "weighted avg       0.77      0.76      0.76       600\n",
            "\n",
            "true negative :  239\n",
            "false positive:  48\n",
            "false negative:  95\n",
            "true positive :  218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME8008LXIoI2"
      },
      "source": [
        "# Features Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "lmjYl7NzIsMR",
        "outputId": "96757613-9e39-45b9-cf04-b30e55929398"
      },
      "source": [
        "best_model = model_lr.best_estimator_\n",
        "coeff = best_model['LR'].coef_\n",
        "features_coeff = {'Feature_Names': list(X_test_features.columns), 'Coefficients': list(coeff[0])}\n",
        "feature_importance = pd.DataFrame(data=features_coeff)\n",
        "\n",
        "top_5 = feature_importance.sort_values(by=['Coefficients'], ascending=False).head(5)\n",
        "bottom_5 = feature_importance.sort_values(by=['Coefficients'], ascending=False).tail(5)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "d = pd.concat([top_5, bottom_5], axis=0)\n",
        "d.plot.barh(x=\"Feature_Names\",y=\"Coefficients\", color='slategray', figsize = (10,5))\n",
        "plt.title(\"Top and bottom 5 Coefficient Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUu_Bosg_rj"
      },
      "source": [
        "# Selecting 5 random misclassfied examples for analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E10oy6ZIRljZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "3a914d4f-d473-41ed-a546-1d318822ca1f"
      },
      "source": [
        "## Select 5 random incorrect predictions\n",
        "df_test['Prediction'] = y_pred\n",
        "df_test['Probablity'] = y_probablity\n",
        "filter = df_test['Prediction'] != df_test['Polarity']\n",
        "df_test.where(filter, inplace=True)\n",
        "incorrect_pred = df_test.dropna().sample(5, random_state = 22)\n",
        "incorrect_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>clean_sentence</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Probablity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>I highly doubt that anyone could ever like thi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i highly doubt that anyone could ever like thi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>Raw and sublimely moving.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>raw and sublimely move</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>You will leave the theater wanting to go out a...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-PRON- will leave the theater want to go out a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.433548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>It's a shame to see good actors like Thomerson...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-PRON- a shame to see good actor like thomerso...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.756953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>I keep watching it over and over.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>i keep watch -PRON- over and over</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.419946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ...  Probablity\n",
              "510  I highly doubt that anyone could ever like thi...  ...    0.560196\n",
              "271                        Raw and sublimely moving.    ...    0.405271\n",
              "417  You will leave the theater wanting to go out a...  ...    0.433548\n",
              "154  It's a shame to see good actors like Thomerson...  ...    0.756953\n",
              "581                I keep watching it over and over.    ...    0.419946\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_4oF9UnY8ni"
      },
      "source": [
        "**Example 1**:  *true is 0,  prediction is 1*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAF9XzOM5c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ac86cf-5f0c-4408-c1a0-37b63fef13e5"
      },
      "source": [
        "# Print the Sentence and cleaned sentence of Example 1\n",
        "print(f\"Sentence: {incorrect_pred.iloc[0,0]}\")\n",
        "print(f\"\\nCleaned Sentence: {incorrect_pred.iloc[0,2]}\")\n",
        "\n",
        "# Get the feature coefficient values of the tokens and ngrams of the sentence\n",
        "txt = incorrect_pred.iloc[0,2].replace(\"-PRON-\", \"pron\")\n",
        "tokens = txt.split()\n",
        "tri_grams = [\" \".join(items) for items in list(ngrams(tokens, 3))]\n",
        "bi_grams = [\" \".join(items) for items in list(ngrams(tokens, 2))]\n",
        "q1 = feature_importance.query(f'Feature_Names in  {tokens}')\n",
        "q2 = feature_importance.query(f'Feature_Names in  {tri_grams}')\n",
        "q3 = feature_importance.query(f'Feature_Names in  {bi_grams}')\n",
        "\n",
        "print(f\"\\n\\n{pd.concat([q1,q2,q3]).reset_index(drop=True)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I highly doubt that anyone could ever like this trash.  \n",
            "\n",
            "Cleaned Sentence: i highly doubt that anyone could ever like this trash\n",
            "\n",
            "\n",
            "  Feature_Names  Coefficients\n",
            "0        anyone      0.210849\n",
            "1         could      0.080199\n",
            "2          ever     -0.341351\n",
            "3        highly      0.137826\n",
            "4          like      0.390760\n",
            "5         trash     -0.285516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6THkYX2j8opG"
      },
      "source": [
        "- The Coefficient of the word 'like' is dominating and is pulling the prediction to 1 along with other words positive words 'anyone' and 'highly'.\n",
        "\n",
        "- Although, the model has learned the word 'trash' correctly with a negative coefficient. The overall weightage of words with positive coefficients is more and making the model predict incorrectly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB1bey6eZBU_"
      },
      "source": [
        "**Example 2**: *true is 1,  prediction is 0*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INh5ncKsU6QL",
        "outputId": "293df22d-5fb4-471d-b634-0546de10e1fc"
      },
      "source": [
        "# Print the Sentence and cleaned sentence of Example 1\n",
        "print(f\"Sentence: {incorrect_pred.iloc[1,0]}\")\n",
        "print(f\"\\nClean Sentence: {incorrect_pred.iloc[1,2]}\")\n",
        "\n",
        "# Get the feature coefficient values of the tokens and ngrams of the sentence\n",
        "txt = incorrect_pred.iloc[1,2].replace(\"-PRON-\", \"pron\")\n",
        "tokens = txt.split()\n",
        "tri_grams = [\" \".join(items) for items in list(ngrams(tokens, 3))]\n",
        "bi_grams = [\" \".join(items) for items in list(ngrams(tokens, 2))]\n",
        "q1 = feature_importance.query(f'Feature_Names in  {tokens}')\n",
        "q2 = feature_importance.query(f'Feature_Names in  {tri_grams}')\n",
        "q3 = feature_importance.query(f'Feature_Names in  {bi_grams}')\n",
        "print(f\"\\n\\n{pd.concat([q1,q2,q3]).reset_index(drop=True)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: Raw and sublimely moving.  \n",
            "\n",
            "Clean Sentence: raw and sublimely move\n",
            "\n",
            "\n",
            "  Feature_Names  Coefficients\n",
            "0          move     -0.269988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKmFoVCzm4jo"
      },
      "source": [
        "- The word 'move' has a negative Coefficient, and thus the model is predicting '0' .\n",
        "\n",
        "- The crucial words 'raw' and 'sublimely' are not present in the Train set. (See below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkRgBBckN1bQ",
        "outputId": "d7521f02-747f-4906-9d2e-9a4d9ab4f812"
      },
      "source": [
        "# Find out the word frequency of th word 'standdout' in Train set and 'scene\n",
        "print(f\"DF of 'raw' in Train:{sum(df_train['clean_sentence'].apply(lambda x:True if' raw 'in x else False))}\")\n",
        "print(f\"\\nDF of 'sublimely' in Train:{sum(df_train['clean_sentence'].apply(lambda x:True if' sublimely 'in x else False))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DF of 'raw' in Train:0\n",
            "\n",
            "DF of 'sublimely' in Train:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayB72Zv0ZDbX"
      },
      "source": [
        "**Example 3**:  *true is 1,  prediction is 0*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReeG0HngWM3K",
        "outputId": "886d2e34-1791-4abf-cdf0-ef48d4bb1a01"
      },
      "source": [
        "# Print the Sentence and cleaned sentence of Example 1\n",
        "print(f\"Sentence: {incorrect_pred.iloc[2,0]}\")\n",
        "print(f\"\\nClean Sentence: {incorrect_pred.iloc[2,2]}\")\n",
        "\n",
        "# Get the feature coefficient values of the tokens and ngrams of the sentence\n",
        "txt = incorrect_pred.iloc[2,2].replace(\"-PRON-\", \"pron\")\n",
        "tokens = txt.split()\n",
        "tri_grams = [\" \".join(items) for items in list(ngrams(tokens, 3))]\n",
        "bi_grams = [\" \".join(items) for items in list(ngrams(tokens, 2))]\n",
        "q1 = feature_importance.query(f'Feature_Names in  {tokens}')\n",
        "q2 = feature_importance.query(f'Feature_Names in  {tri_grams}')\n",
        "q3 = feature_importance.query(f'Feature_Names in  {bi_grams}')\n",
        "print(f\"\\n\\n{pd.concat([q1,q2,q3]).reset_index(drop=True)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: You will leave the theater wanting to go out and dance under the stars.  \n",
            "\n",
            "Clean Sentence: -PRON- will leave the theater want to go out and dance under the star\n",
            "\n",
            "\n",
            "  Feature_Names  Coefficients\n",
            "0            go     -0.274081\n",
            "1         leave     -0.496006\n",
            "2          star      0.047943\n",
            "3       theater     -0.087853\n",
            "4          want      0.159297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdL2UGSjnEhH"
      },
      "source": [
        "- This example has negative words such as 'leave' and 'go' with high negative coefficients.\n",
        "\n",
        "- The meaning of the sentence is difficult to understand for a model. Even though most of the words have a 'negative' sentiment to them, when used correctly, the overall sentence has a positive sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5417PT_ZF1A"
      },
      "source": [
        "**Example 4** :   *true is 0,  prediction is 1*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twJ7ugPwWR0z",
        "outputId": "a748bf39-6d8f-4d0c-bd12-760a52522ccb"
      },
      "source": [
        "# Print the Sentence and cleaned sentence of Example 1\n",
        "print(f\"Sentence: {incorrect_pred.iloc[3,0]}\")\n",
        "print(f\"\\nCleaned Sentence: {incorrect_pred.iloc[3,2]}\")\n",
        "\n",
        "# Get the feature coefficient values of the tokens and ngrams of the sentence\n",
        "txt = incorrect_pred.iloc[3,2].replace(\"-PRON-\", \"pron\")\n",
        "tokens = txt.split()\n",
        "tri_grams = [\" \".join(items) for items in list(ngrams(tokens, 3))]\n",
        "bi_grams = [\" \".join(items) for items in list(ngrams(tokens, 2))]\n",
        "q1 = feature_importance.query(f'Feature_Names in  {tokens}')\n",
        "q2 = feature_importance.query(f'Feature_Names in  {tri_grams}')\n",
        "q3 = feature_importance.query(f'Feature_Names in  {bi_grams}')\n",
        "print(f\"\\n\\n{pd.concat([q1,q2,q3]).reset_index(drop=True)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: It's a shame to see good actors like Thomerson and James make a living in a mess like this.  \n",
            "\n",
            "Cleaned Sentence: -PRON- a shame to see good actor like thomerson and james make a living in a mess like this\n",
            "\n",
            "\n",
            "  Feature_Names  Coefficients\n",
            "0         actor      0.096411\n",
            "1          good      2.876354\n",
            "2          like      0.390760\n",
            "3          make      0.078229\n",
            "4          mess      0.002378\n",
            "5           see     -0.098336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_sdCTchTobk"
      },
      "source": [
        "- In this example, the model's prediction is dominated by the words 'good' and 'like'. \n",
        "\n",
        "- The negative term 'shame', which is changing the whole meaning to negative sentiment, is not present in the features as the word 'shame' was not present in Train data (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuQhljnGUNMd",
        "outputId": "f28ac314-7187-4bc5-9129-9862a94eae63"
      },
      "source": [
        "print(f\"DF of 'shame' in Train: {sum(df_train['clean_sentence'].apply(lambda x:True if' shame 'in x else False))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DF of 'shame' in Train: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly4ED0AnZIKZ"
      },
      "source": [
        "**Example 5** : *true is 1,  prediction is 0*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX3Slck_WWD9",
        "outputId": "a271d363-52a6-4c3e-bb98-8f6337ed76b0"
      },
      "source": [
        "# Print the Sentence and cleaned sentence of Example 1\n",
        "print(f\"Sentence: {incorrect_pred.iloc[4,0]}\")\n",
        "print(f\"\\nCleaned Sentence: {incorrect_pred.iloc[4,2]}\")\n",
        "\n",
        "# Get the feature coefficient values of the tokens and ngrams of the sentence\n",
        "txt = incorrect_pred.iloc[4,2].replace(\"-PRON-\", \"pron\")\n",
        "tokens = txt.split()\n",
        "tri_grams = [\" \".join(items) for items in list(ngrams(tokens, 3))]\n",
        "bi_grams = [\" \".join(items) for items in list(ngrams(tokens, 2))]\n",
        "q1 = feature_importance.query(f'Feature_Names in  {tokens}')\n",
        "q2 = feature_importance.query(f'Feature_Names in  {tri_grams}')\n",
        "q3 = feature_importance.query(f'Feature_Names in  {bi_grams}')\n",
        "print(f\"\\n\\n{pd.concat([q1,q2,q3]).reset_index(drop=True)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: I keep watching it over and over.  \n",
            "\n",
            "Cleaned Sentence: i keep watch -PRON- over and over\n",
            "\n",
            "\n",
            "  Feature_Names  Coefficients\n",
            "0          keep     -0.327439\n",
            "1         watch     -0.059905\n",
            "2    watch pron      0.017602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVU8VCq2UiPV"
      },
      "source": [
        "- In this example, the word 'keep' is dominating and has a negative coefficient.\n",
        "- The word 'keep' has a neutral sentiment, but the model has learned high negative weights. More training data would help model correct such errors.\n",
        "\n"
      ]
    }
  ]
}