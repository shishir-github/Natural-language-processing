{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Spam dectection using NLP- - RF and XGB - V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE8q2zLARI4c"
      },
      "source": [
        "### Importing the required modules/packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LswEEonkRI4k",
        "outputId": "e19b2cae-9b4f-4ccc-8413-ce3e4d0a4124"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion, TransformerMixin\n",
        "from mlxtend.feature_selection import ColumnSelector\n",
        "from sklearn.compose import ColumnTransformer\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTQo0z49RI4l"
      },
      "source": [
        "### Loading file and looking into the dimensions of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdbQiaN0RI4l",
        "outputId": "b7707aa2-7dec-4bf9-e678-a54da5836034"
      },
      "source": [
        "df = pd.read_csv(\"spamraw_train.csv\")\n",
        "pd.set_option('display.max_colwidth',100)\n",
        "\n",
        "print(f\"Shape of Data --> {df.shape}\\n\")\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Data --> (5000, 3)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "NtPGU3VgRI4m",
        "outputId": "0ec4094c-fe23-45c6-c39b-776ad521ab87"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sms_text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                           sms_text  spam\n",
              "0   1  Hope you are having a good week. Just checking in     0\n",
              "1   2                            K..give back my thanks.     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XH5CltGnvaR"
      },
      "source": [
        "## **Data Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK58YKAHRI4n"
      },
      "source": [
        "### Functions to Create new features and cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HMa2us8YiA-i",
        "outputId": "3c647480-be24-48b1-b4ac-597f685f4b8b"
      },
      "source": [
        "string.punctuation"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VwBYY-Oi9cJ"
      },
      "source": [
        "specialChar = '#$%&()*+-/:;<=>?@[\\]^_`{|}~'\r\n",
        "moneysigns = '$£'"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD34kSfITdqr"
      },
      "source": [
        "spamwords = [\"free\",\"recieve\", \"freemsg\",\"winner\", \"urgent!\",\r\n",
        "             \"charged\",\"SMS\",\"claim\", \"guaranteed\", \"end\"]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eEM4AN8RI4n"
      },
      "source": [
        "## Creat punc\n",
        "import re\n",
        "\n",
        "def pc_SpecialChar(text):\n",
        "    punct_count = sum([1 for char in text if char in specialChar])\n",
        "    return (punct_count/(len(text) - text.count(' ')))*100\n",
        "\n",
        "def clean_data(text):\n",
        "    punct = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    splt = re.split('\\W+',punct)    \n",
        "    txt = [nltk.PorterStemmer().stem(word) for word in splt if word not in nltk.corpus.stopwords.words('english')]\n",
        "    return \"  \".join(txt)\n",
        "\n",
        "def count_caps(text):\n",
        "    splt = re.split('\\W+',text)\n",
        "    return len([word for word in splt if word.isupper()])\n",
        "\n",
        "def count_exlc(text):\n",
        "    i = 0\n",
        "    for char in text:\n",
        "      if char == '!':\n",
        "        i += 1\n",
        "    return i \n",
        "\n",
        "def count_fullstop(text):\n",
        "    i = 0\n",
        "    for char in text:\n",
        "      if char == '.':\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "def count_at(text):\n",
        "    i = 0\n",
        "    for char in text:\n",
        "      if char == '@':\n",
        "        i += 1\n",
        "    return i\n",
        "# Has a number with more than 3 digits\n",
        "def count_num(text):\n",
        "    pattern = re.compile(r'\\d\\d\\d.*')\n",
        "    if len(pattern.findall(text)) > 0:\n",
        "      return 1\n",
        "    else: \n",
        "      return 0\n",
        "\n",
        "# Has a url\n",
        "def has_URL(text):\n",
        "    pattern1 = re.compile(r'www.*')\n",
        "    pattern2 = re.compile(r'https:*')\n",
        "    if len(pattern1.findall(text))  > 0:\n",
        "      return 1\n",
        "    elif len(pattern1.findall(text)) > 0:\n",
        "      return 1\n",
        "    else: \n",
        "      return 0\n",
        "\n",
        "def has_moneysymbol(text):\n",
        "    i = 0\n",
        "    for char in text:\n",
        "      if char in '$£':\n",
        "        i += 1\n",
        "    return i \n",
        "\n",
        "def count_spamwords(text):\n",
        "    i = 0\n",
        "    for tokens in text.split():\n",
        "      if tokens in spamwords:\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "\n",
        "\n",
        "def has_money(text):\n",
        "    pattern1 = re.compile(r'[$£]\\d[.\\d][.\\d]\\d*')\n",
        "    if len(pattern1.findall(text))  > 0:\n",
        "      return 1\n",
        "    else: \n",
        "      return 0\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1w7ux3qmKmY"
      },
      "source": [
        "######################## Create new features Train and Test Data ########################\r\n",
        "#- New features are created - \r\n",
        "#- 1) text_length (the total length of the text)\r\n",
        "#- 2) Punct_pc (the percentage of punctuations in the text)\r\n",
        "# -3) Total number of Caps words\r\n",
        "# -4) Total number of words with exclamations in text\r\n",
        "\r\n",
        "## New features Lexical\r\n",
        "def new_features(df):\r\n",
        "  df[\"SpecialChar_pc\"] = df[\"sms_text\"].apply(lambda x: pc_SpecialChar(x))\r\n",
        "  df[\"text_length\"] = df[\"sms_text\"].apply(lambda x: len(x)-x.count(' '))\r\n",
        "  df[\"caps_count\"] = df[\"sms_text\"].apply(lambda x: count_caps(x))\r\n",
        "  df[\"exclamation_count\"] = df[\"sms_text\"].apply(lambda x: count_exlc(x))\r\n",
        "  df[\"fullstop_count\"] = df[\"sms_text\"].apply(lambda x: count_fullstop(x))\r\n",
        "  df[\"count_at\"] = df[\"sms_text\"].apply(lambda x: count_at(x))\r\n",
        "  df[\"has_num\"] = df[\"sms_text\"].apply(lambda x: count_num(x))\r\n",
        "  df[\"has_url\"] = df[\"sms_text\"].apply(lambda x: has_URL(x))\r\n",
        "  df[\"has_moneysymbol\"] = df[\"sms_text\"].apply(lambda x: has_moneysymbol(x))\r\n",
        "  df[\"has_money\"] = df[\"sms_text\"].apply(lambda x: has_money(x))\r\n",
        "\r\n",
        "  ### Clean the Text\r\n",
        "  df[\"Clean_text\"] = df[\"sms_text\"].apply(lambda x: clean_data(x))\r\n",
        "  df[\"count_spamwords\"] = df[\"Clean_text\"].apply(lambda x: count_spamwords(x))\r\n",
        "  return df\r\n",
        "\r\n",
        "df = new_features(df)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxgE89zLngg_"
      },
      "source": [
        "y_train = df[\"spam\"]\r\n",
        "X_train = df.drop(\"spam\",axis=1)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "CaLIwjtWlakp",
        "outputId": "174c733e-82d6-4471-aeca-b1ef2212f148"
      },
      "source": [
        "X_train.loc[X_train.sms_text == 'spam', :]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sms_text</th>\n",
              "      <th>SpecialChar_pc</th>\n",
              "      <th>text_length</th>\n",
              "      <th>caps_count</th>\n",
              "      <th>exclamation_count</th>\n",
              "      <th>fullstop_count</th>\n",
              "      <th>count_at</th>\n",
              "      <th>has_num</th>\n",
              "      <th>has_url</th>\n",
              "      <th>has_moneysymbol</th>\n",
              "      <th>has_money</th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>count_spamwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, sms_text, SpecialChar_pc, text_length, caps_count, exclamation_count, fullstop_count, count_at, has_num, has_url, has_moneysymbol, has_money, Clean_text, count_spamwords]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5ytibkoZRXc"
      },
      "source": [
        "Custom Transformer to select the Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I3H3jnWYhO5"
      },
      "source": [
        "## Customer transformer to Select features \r\n",
        "class ColumnExtractor(TransformerMixin):\r\n",
        "    def __init__(self, cols):\r\n",
        "        self.cols = cols\r\n",
        "\r\n",
        "    def fit(self, X, y=None):\r\n",
        "        # stateless transformer\r\n",
        "        return self\r\n",
        "\r\n",
        "    def transform(self, X):\r\n",
        "        # assumes X is a DataFrame\r\n",
        "        Xcols = pd.Series(X[self.cols])\r\n",
        "        return (Xcols)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOeV7GlCxjKd"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rZbs5qrIneo"
      },
      "source": [
        "## Model Training\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\r\n",
        "from sklearn.model_selection import KFold, cross_val_score\r\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc9BA6qk0mw_"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwzkCGaTitSU",
        "outputId": "4df25f51-d118-47e7-f311-1d121056d71a"
      },
      "source": [
        "lex_features = list(X_train.select_dtypes(exclude='O').columns)\r\n",
        "print(lex_features)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['id', 'SpecialChar_pc', 'text_length', 'caps_count', 'exclamation_count', 'fullstop_count', 'count_at', 'has_num', 'has_url', 'has_moneysymbol', 'has_money', 'count_spamwords']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUWILbsmjQSK"
      },
      "source": [
        "num_cols =['SpecialChar_pc', 'text_length', 'caps_count', 'exclamation_count', 'fullstop_count', 'count_at', 'has_num', \\\r\n",
        "'has_url', 'has_moneysymbol', 'has_money', 'count_spamwords']"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go1XrcIu8bkH"
      },
      "source": [
        "text_pipe = Pipeline([('select_text', ColumnExtractor(cols=\"Clean_text\")),('tfidf', TfidfVectorizer())])\r\n",
        "num_pipe = Pipeline([('scaler', ColumnTransformer([('scaler', MinMaxScaler(),num_cols)],\r\n",
        "                                                             ))])\r\n",
        "full_pipe = Pipeline([\r\n",
        "    ('Fu', FeatureUnion([(\"text\", text_pipe), (\"num\",num_pipe)])),\r\n",
        "    ('RF', RandomForestClassifier(random_state=123))\r\n",
        "])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQ0SCbqpJai"
      },
      "source": [
        "param_grid = {\r\n",
        "                 \"RF__max_depth\": [25, None],\r\n",
        "                 \"RF__n_estimators\": [15,20,25],\r\n",
        "                 \"RF__max_features\" : [50,60,'auto'],\r\n",
        "                 \"RF__class_weight\":['balanced'],\r\n",
        "                 'Fu__text__tfidf__max_df': [0.3],\r\n",
        "                #'Fu__text__tfidf__min_df': [],\r\n",
        "              'Fu__text__tfidf__ngram_range': [(1,4),(1,1)]\r\n",
        "              \r\n",
        "                } "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJoiLNd0yJmu",
        "outputId": "1f653626-2b1c-445f-cce7-bfc49b3029f1"
      },
      "source": [
        "rf_grid = GridSearchCV(full_pipe,param_grid,cv=2,n_jobs=-1, verbose=3, scoring='f1_macro')\r\n",
        "rf_grid_fit = rf_grid.fit(X_train, y_train)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   20.4s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bTvCcNb1TND",
        "outputId": "ac4f0c64-6c34-485a-824f-7958f81093ad"
      },
      "source": [
        "est = rf_grid_fit.best_estimator_\r\n",
        "print(rf_grid_fit.best_score_)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9617019102204918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-EFWqAM26UW",
        "outputId": "b474246a-60ed-4275-9486-95482d8cfbea"
      },
      "source": [
        "#print(est[-2])\r\n",
        "rf_grid_fit.best_params_"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Fu__text__tfidf__max_df': 0.3,\n",
              " 'Fu__text__tfidf__ngram_range': (1, 1),\n",
              " 'RF__class_weight': 'balanced',\n",
              " 'RF__max_depth': 25,\n",
              " 'RF__max_features': 50,\n",
              " 'RF__n_estimators': 25}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_y1xQSgBsFO"
      },
      "source": [
        "**XGboost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmyXM20Wo4ez"
      },
      "source": [
        "from xgboost import XGBClassifier\r\n",
        "full_pipe_xgb = Pipeline([\r\n",
        "    ('Fu_xgb', FeatureUnion([(\"text\", text_pipe), (\"num\",num_pipe)])),\r\n",
        "    ('XGB', XGBClassifier(random_state=123))\r\n",
        "])\r\n",
        "param_grid = {\r\n",
        "                 \"XGB__max_depth\": [10,12, None],\r\n",
        "                 \"XGB__n_estimators\": [120,125],\r\n",
        "                 \"XGB__max_features\" : [35,38,39,'auto'],\r\n",
        "                 'Fu_xgb__text__tfidf__max_df': [0.3,0.4],\r\n",
        "                'Fu_xgb__text__tfidf__min_df': [0.1],\r\n",
        "              'Fu_xgb__text__tfidf__ngram_range': [(1,4)]\r\n",
        "              \r\n",
        "                } "
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdB8NJioB_Ju",
        "outputId": "03d0a658-6ec9-4fba-bc20-8265d555c352"
      },
      "source": [
        "xgb_grid = GridSearchCV(full_pipe_xgb,param_grid,cv=3,n_jobs=-1, verbose=3, scoring='f1_macro')\r\n",
        "xgb_grid_fit = xgb_grid.fit(X_train, y_train)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   17.8s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXlUUW1NWGw4",
        "outputId": "742fc7e6-26e8-4040-bfab-11a748a7dd38"
      },
      "source": [
        "print(xgb_grid_fit.best_score_)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9550396102823099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e8w-72uWEAd",
        "outputId": "ec4b1c96-eb66-46a8-8075-233b5839bb7a"
      },
      "source": [
        "#print(est[-2])\r\n",
        "xgb_grid_fit.best_params_"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Fu_xgb__text__tfidf__max_df': 0.3,\n",
              " 'Fu_xgb__text__tfidf__min_df': 0.1,\n",
              " 'Fu_xgb__text__tfidf__ngram_range': (1, 4),\n",
              " 'XGB__max_depth': 10,\n",
              " 'XGB__max_features': 35,\n",
              " 'XGB__n_estimators': 125}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh2EBr8bd0rr"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Ae-Fgsd8IB"
      },
      "source": [
        "X_test = pd.read_csv(\"spamraw_test.csv\")\r\n",
        "\r\n",
        "## New features Lexical\r\n",
        "X_test = new_features(X_test)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzrvYKPSSIdt",
        "outputId": "798a7e7e-5be1-421c-fd8d-bf750fc581b3"
      },
      "source": [
        "list(X_test.columns)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'sms_text',\n",
              " 'SpecialChar_pc',\n",
              " 'text_length',\n",
              " 'caps_count',\n",
              " 'exclamation_count',\n",
              " 'fullstop_count',\n",
              " 'count_at',\n",
              " 'has_num',\n",
              " 'has_url',\n",
              " 'has_moneysymbol',\n",
              " 'has_money',\n",
              " 'Clean_text',\n",
              " 'count_spamwords']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOxgARCTwwx-"
      },
      "source": [
        "## Prediction XGBoost\r\n",
        "y_pred_xg = xgb_grid_fit.predict(X_test)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mALAj2-iex8R"
      },
      "source": [
        "## Prediction Random Forest\r\n",
        "y_pred_rand = rf_grid_fit.predict(X_test)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3CFIg7me4UI"
      },
      "source": [
        "## Final Model \r\n",
        "## Load submission file and update predictions using all models\r\n",
        "predvt1 = pd.DataFrame(y_pred_rand, columns=[\"Predicted\"])\r\n",
        "predvt1.to_csv(\"rf.csv\", index=False)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42QapM7Gftqi"
      },
      "source": [
        "## Final Model \r\n",
        "## Load submission file and update predictions using all models\r\n",
        "predvt2 = pd.DataFrame(y_pred_xg, columns=[\"Predicted\"])\r\n",
        "predvt2.to_csv(\"xg.csv\", index=False)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER873OtCxqfd"
      },
      "source": [
        ""
      ],
      "execution_count": 111,
      "outputs": []
    }
  ]
}